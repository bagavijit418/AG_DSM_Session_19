{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. What are the three stages to build the hypotheses or model in machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three stages are- \n",
    "1. Model building - Data Preparation, Training and Test set generation, Algorithm Training\n",
    "\n",
    "2. Model testing - Prediction and Evaluation of Test Data\n",
    "3. Applying the model - Deployment and Monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. What is the standard approach to supervised learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supervised learning are performed using labeled examples, such as an input where the desired\n",
    "output is known. The learning algorithm receives a set of inputs along with the corresponding correct outputs, and the\n",
    "algorithm learns by comparing its actual output with correct outputs to find errors. It then modifies the model\n",
    "accordingly. Through methods like classification, regression, prediction and gradient boosting, supervised\n",
    "learning uses patterns to predict the values of the label on additional unlabeled data. Supervised learning is\n",
    "commonly used in applications where historical data predicts likely future events. \n",
    "\n",
    "For example, it can \n",
    "anticipate when credit card transactions are likely to be fraudulent or which insurance customer is likely to file\n",
    "claim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. What is Training set and Test set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Set -A data set used to train the model. Specific features are picked up from the training set for training purpose.\n",
    "\n",
    "Test Set -A data set used to measure how well the model performs at making predictions on the test data based on the training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. What is the general principle of an ensemble method and what is bagging and boosting in ensemble method?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general principle of an ensemble method is to combine the predictions of several models built with a given learning algorithm in order to improve robustness over a single model.\n",
    "\n",
    "\n",
    "Bagging- A method in ensemble for improving unstable estimation or classification schemes. Bagging both can reduce errors by reducing the variance term.\n",
    "\n",
    "Boosting- A method is used sequentially to reduce the bias of the combined model. Boosting can reduce errors by reducing the variance term.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. How can you avoid overfitting ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overfitting refers to a model that models the training data too well. Overfitting happens when a model learns the detail and noise in the training data to the extent that it negatively impacts the performance of the model on new data. This means that the noise or random fluctuations in the training data is picked up and learned as concepts by the model. This can eb avoided by following way-\n",
    "\n",
    "1. Cross-Validation : Cross Validation in its simplest form is a one round validation, where we leave one sample as in-time validation and rest for training the model. But for keeping lower variance a higher fold cross validation is preferred.\n",
    "\n",
    "2. Early Stopping : Early stopping rules provide guidance as to how many iterations can be run before the learner begins to over-fit.\n",
    "\n",
    "3. Pruning : Pruning is used extensively while building CART models. It simply removes the nodes which add little predictive power for the problem in hand.\n",
    "\n",
    "4. Regularization : It introduces a cost term for bringing in more features with the objective function. Hence, it tries to push the coefficients for many variables to zero and hence reduce cost term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
